[
    {
        "paper_name": "Research paper 1.pdf",
        "abstract": "",
        "content": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery\nGenerated by AI Scientists\nPengsong Zhang1*†, Xiang Hu2†, Guowei Huang3†, Yang Qi4†, Heng Zhang5†,\nXiuxu Li2, Jiaxing Song6, Jiabin Luo7, Yijiang Li8, Shuo Yin9, Chengxiao Dai10, Eric Hanchen\nJiang11, Xiaoyan Zhou2, Zhenfei Yin12, Boqin Yuan8, Jing Dong13, Guinan Su14, Guanren Qiao15,\nHaiming Tang16, Anghong Du17, Lili Pan18*, Zhenzhong Lan2*, Xinyu Liu1\n1University of Toronto,2Westlake University,3University of Manchester,4University of Utah,5Istituto Italiano di Tecnologia,\nUniversit `a degli Studi di Genova,6Zhejiang University,7Peking University,8University of California, San Diego,9Tsinghua\nUniversity,10University of Sydney,11University of California, Los Angeles,12University of Oxford,13Columbia University,\n14Max Planck Institute for Intelligent Systems,15The Chinese University of Hong Kong,16National University of Singapore,\n17University of Birmingham,18University of Electronic Science and Technology of China\nAbstract\nRecent advances in large language models (LLMs) have en-\nabled AI agents to autonomously generate scientific pro-\nposals, conduct experiments, author papers, and perform\npeer reviews. Yet this flood of AI-generated research con-\ntent collides with a fragmented and largely closed publica-\ntion ecosystem. Traditional journals and conferences rely on\nhuman peer review, making them difficult to scale and of-\nten reluctant to accept AI-generated research content; exist-\ning preprint servers (e.g. arXiv) lack rigorous quality-control\nmechanisms. Consequently, a significant amount of high-\nquality AI-generated research lacks appropriate venues for\ndissemination, hindering its potential to advance scientific\nprogress. To address these challenges, we introduce aiXiv, a\nnext-generation open-access platform for human and AI sci-\nentists. Its multi-agent architecture allows research proposals\nand papers to be submitted, reviewed, and iteratively refined\nby both human and AI scientists. "
    },
    {
        "paper_name": "Research paper 10.pdf",
        "abstract": "",
        "content": " \nhttps://iaeme.com/Home/journal/IJAIML  163 editor@iaeme.com  International Journal of Artificial Intelligence & Machine Learning (IJAIML)   \nVolume 3, Issue 2, July-Dec 2024, pp. 163-172. Article ID: IJAIML _03_02_012 \nAvailable online at https://iaeme.com/Home/issue/IJAIML?Volume=3&Issue=2  \nImpact Factor (2024): 3.56 (Based on Google Scholar Citation)  \nJournal ID: 9339 -1263 , DOI: https://doi.org/ 10.5281/zenodo.13752915  \n \n© IAEME  Publication  \nARTIFICIAL INTELLIGENCE AND MACHINE \nLEARNING: CURRENT DEVELOPMENTS AND \nFUTURE PROSPECTS  \nPooja N egi \nAssistant Professor  (Faculty of Education ), \nAmrapali University , Haldwani, Nainital , India  \nPrashant Rajput  \nAssociate professor and IT Head , \nDepartment of Computer Science and Engineering , \nAmrapali University , Haldwani, Nainital , India  \nABSTRACT  \nArtificial Intelligence (AI) and Machine Learning (ML) have undergone remarkable \nprogress in the past ten years, resulting in profound effects on multiple sectors such as \nhealthcare, finance, and transportation. This research paper provides  an in -depth \nanalysis of the cur rent advancements in AI and ML, explores the latest technologies and \nmethodologies, and discusses  future directions and challenges. Through a detailed \nexamination of contemporary trends and illustrative case studies, this paper seeks to \nprovide a thorough understanding of the evolution of AI and ML, as well as their \npotential societal impacts and implications.  \nThis paper also investigates the present landscape of AI and ML technologies, \nreviews recent progress, and considers future directions. Through a detailed analysis \nof improvements in algorithms, hardware, and practical applications, along with a \ndiscussion  on ethical and societal concerns, the paper aims to deliver a thorough \noverview of the rapidly evolving AI and ML fields.  \nKeywords:  Artificial Intelligence (AI), Machine Learning (ML), Technological \nAdvancements, Ethical Implications, Future Directions  \n \nCit"
    },
    {
        "paper_name": "Research paper 11.pdf",
        "abstract": "",
        "content": "2026-01-22 Work in progress.\nBayesianVLA: Bayesian Decomposition of Vision Language Action\nModels via Latent Action Queries\nShijie Lian1,2, *Bin Yu2,4, *Xiaopeng Lin2,5, *Laurence T. Yang6,1,†Zhaolong Shen2,7\nChangti Wu2,8Yuzhuo Miao1,2Cong Huang2,3Kai Chen2,3,9,†\n1HUST2ZGCA3ZGCI4HIT5HKUST(GZ)6ZZU7BUAA8ECNU9DeepCybo\n/githubhttps://github.com/ZGC-EmbodyAI/BayesianVLA\nAbstract\nVision-Language-Action (VLA) models have shown promise in robot manipulation but of-\nten struggle to generalize to new instructions or complex multi-task scenarios. We identify a\ncritical pathology in current training paradigms where goal-driven data collection creates a\ndataset bias. In such datasets, language instructions are highly predictable from visual obser-\nvations alone, causing the conditional mutual information between instructions and actions\nto vanish, a phenomenon we termInformation Collapse. Consequently, models degener-\nate into vision-only policies that ignore language constraints and fail in out-of-distribution\n(OOD) settings. To address this, we proposeBayesianVLA, a novel framework that en-\nforces instruction following via Bayesian decomposition. By introducing learnableLatent\nAction Queries, we construct a dual-branch architecture to estimate both a vision-only prior\np(a|v)and a language-conditioned posteriorπ(a|v, ℓ). We then optimize the policy\nto maximize the conditional Pointwise Mutual Information (PMI) between actions and in-\nstructions. This objective effectively penalizes the vision shortcut and rewards actions that\nexplicitly explain the language command. Without requiring new data, BayesianVLA sig-\nnificantly improves generalization. Extensive experiments across on SimplerEnv and Robo-\nCasa demonstrate substantial gains, including an11.3%improvement on the challenging\nOOD SimplerEnv benchmark, validating the ability of our approach to robustly ground lan-\nguage in action.\n1 Introduction\nVision-Language-Action (VLA) models (Kim et al., 2024; Liu et al., 2025; Bjorck"
    },
    {
        "paper_name": "Research paper 12.pdf",
        "abstract": "",
        "content": "Pure and Applied Mathematics Journal  \n2025, V ol. 14, No. 5, pp. 114 -119 \nhttps://doi.org/10.11648/j.pamj.20251405.12   \n \n \n*Corresponding author:  \nReceived: 20 July 2025; Accepted: 12 August 2025; Published: 25 September 2025  \n Copyright: © The Author(s), 2025 . Published by Science Publishing Group. This is an Open Access  article, distributed \nunder the terms of the Creative Commons Attribution 4.0 License ( http://creativecommons.org/licenses/by/4.0/ ), which \npermits unrestricted use, distribution and reproduction in any medium, provided the original work is properly cited.  \n \n \nResearch Article  \nMachine Learning (ML) and Artificial Intelligence (AI) \nApproaches to Unstructured Data  \nFarha Khan1, *, Pratima Ojha1, Ghizal Firdous Ansari2 \n1Department of Mathematics, Madhyanchal Professional University, Bhopal,  India  \n2Department of Physics, Madhyanchal Professional University, Bhopal,  India  \n \nAbstract  \nThis study explores the application of machine learning (ML) and artificial intelligence (AI)  techniques to analyze unstructured \ntextual data, focusing on topic modeling, sentiment detection, and behavioral prediction. We employ multinomial document \nmodels and unsupervised learning strategies to extract latent topics and evaluate the emotional and  conversational drivers \nsocial media posts. A major contribution is the implementation of Behavior Dirichlet Probability Model (BDPM) which \nuser moods and behaviors through unstructured textual data.  The results validate the hypothesis of t he model's ability to \nand guess behavior patterns with high accuracy, providing actionable insights for digital marketing strategies,  techniques to \nenhance user interaction and mental wellness evaluation.  \nKeywords  \nMachine Learning, Artificial Intelligence, Unstructured Data, Multinomial Document Model, Predicting Users'  \n \n1. Introduction  \nNowadays, unstructured data makes up the great bulk of the \ndigital world's data. The term \"unstructured data\" may d e"
    },
    {
        "paper_name": "Research paper 13.pdf",
        "abstract": "",
        "content": "International Journal of Information Management 60 (2021) 102383\nAvailable online 8 July 2021\n0268-4012/© 2021 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).Review Article \nArtificial intelligence in information systems research: A systematic \nliterature review and research agenda \nChristopher Collinsa,*, Denis Dennehya, Kieran Conboya, Patrick Mikalefb \naNUI Galway, Upper Newcastle Road, Galway, Ireland \nbNorwegian University of Science and Technology, Høgskoleringen 1, 7491 Trondheim, Norway   \nARTICLE INFO  \nKeywords: \nArtificial intelligence \nAI \nMachine learning \nSystematic literature review \nResearch agenda ABSTRACT  \nAI has received increased attention from the information systems (IS) research community in recent years. There \nis, however, a growing concern that research on AI could experience a lack of cumulative building of knowledge, \nwhich has overshadowed IS research previously. This study addresses this concern, by conducting a systematic \nliterature review of AI research in IS between 2005 and 2020. The search strategy resulted in 1877 studies, of \nwhich 98 were identified as primary studies and a synthesise of key themes that are pertinent to this study is \npresented. In doing so, this study makes important contributions, namely (i) an identification of the current \nreported business value and contributions of AI, (ii) research and practical implications on the use of AI and (iii) \nopportunities for future AI research in the form of a research agenda.   \n1.Introduction \nAI has been claimed to offer transformational potential across sectors \nand industries, ranging from supply chain management (Chi, Huang, & \nGeorge, 2020; Collins, Youngdahl, Jamison, Mobasher, & Gini, 1998; \nNissen & Sengupta, 2006; Rodriguez-Aguilar, Martin, Noriega, Garcia, & \nSierra, 1998 ) to medicine (Ali, Shrestha, Soar, & Wamba, 2018; Cepo -\nlina & Muscolo, 2014; Mettler, Sprenge"
    },
    {
        "paper_name": "Research paper 14.pdf",
        "abstract": "",
        "content": "International Journal of Information Management 60 (2021) 102361\nAvailable online 23 May 2021\n0268-4012/© 2021 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license\n(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).Research Article \nEmotional reactions to robot colleagues in a role-playing experiment \nNina Savelaa,*, Atte Oksanena, Max Pellertb,c,d, David Garciab,c,d \naFaculty of Social Sciences, Tampere University \nbInstitute of Interactive Systems and Data Science, Department of Computer Science and Biomedical Engineering, Graz University of Technology \ncComplexity Science Hub Vienna \ndCenter for Medical Statistics, Informatics and Intelligent Systems, Medical University of Vienna   \nARTICLE INFO  \nKeywords: \nRobot \nWork \nSentiment \nRole-play \nExperiment ABSTRACT  \nWe investigated how people react emotionally to working with robots in three scenario-based role-playing survey \nexperiments collected in 2019 and 2020 from the United States (Study 1: N 1003; Study 2: N 969, Study 3: \nN 1059). Participants were randomly assigned to groups and asked to write a short post about a scenario in \nwhich we manipulated the number of robot teammates or the size of the social group (work team vs. organi -\nzation). Emotional content of the corpora was measured using six sentiment analysis tools, and socio- \ndemographic and other factors were assessed through survey questions and LIWC lexicons and further \nanalyzed in Study 4. The results showed that people are less enthusiastic about working with robots than with \nhumans. Our findings suggest these more negative reactions stem from feelings of oddity in an unusual situation \nand the lack of social interaction.   \n1.Introduction \nPeople have been using automation and working with robots in in-\ndustry fields such as manufacturing for many years. Researchers suggest \nthat the exceptional situation caused by COVID-19 and social distancing \nguidelines will further increase the use"
    },
    {
        "paper_name": "Research paper 15.pdf",
        "abstract": "",
        "content": "International Journal of Information Management 60 (2021) 102331\nAvailable online 19 February 2021\n0268-4012/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license\n(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).Review \nFrom user-generated data to data-driven innovation: A research agenda to \nunderstand user privacy in digital markets \nJose Ramon Sauraa,*, Domingo Ribeiro-Sorianob, Daniel Palacios-Marqu ˘esc \naRey Juan Carlos University, Madrid, Spain \nbIUDESCOOP, Universitat de Valencia, Valencia, Spain \ncUniversitat Politˇecnica de Valˇencia, Valencia, Spain   \nARTICLE INFO  \nKeywords: \nUser-generated data \nData-driven innovation \nUsers ’ privacy \nPrivacy concerns ABSTRACT  \nIn recent years, strategies focused on data-driven innovation (DDI) have led to the emergence and development \nof new products and business models in the digital market. However, these advances have given rise to the \ndevelopment of sophisticated strategies for data management, predicting user behavior, or analyzing their ac-\ntions. Accordingly, the large-scale analysis of user-generated data (UGD) has led to the emergence of user privacy \nconcerns about how companies manage user data. Although there are some studies on data security, privacy \nprotection, and data-driven strategies, a systematic review on the subject that would focus on both UGD and DDI \nas main concepts is lacking. Therefore, the present study aims to provide a comprehensive understanding of the \nmain challenges related to user privacy that affect DDI. The methodology used in the present study unfolds in the \nfollowing three phases; (i) a systematic literature review (SLR); (ii) in-depth interviews framed in the perspec -\ntives of UGD and DDI on user privacy concerns, and finally, (iii) topic-modeling using a Latent Dirichlet allo-\ncation (LDA) model to extract insights related to the object of study. Based on the results, we identify 14 topics \nrelated to the study of"
    },
    {
        "paper_name": "Research paper 2.pdf",
        "abstract": "",
        "content": "https://iaeme.com/Home/journal/ IJAIML         35 editor@iaeme.com  International Journal of Artificial Intelligence & Machine Learning (IJAIML)  \nVolume 3, Issue 1, Jan -June 2024, pp. 35-49. Article ID: IJAIML_03_01_00 4 \nAvailable online at https://iaeme.com/Home/issue/IJAIML?Volume=3&Issue=1  \nImpact Factor (2024): 3.56 (Based on Google Scholar Citation)  \nJournal ID: 9339 -1263 , DOI: https://doi.org/10.17605/OSF.IO/WCN8A  \n \n© IAEME Publication  \n \nAI IN DATA PRIVACY AND SECURITY  \nSiva Karthik Devineni  \nDatabase Consultant, MD, USA  \nABSTRACT  \nThis paper explores the transformative impact of Artificial intelligence on data \nprivacy and security. It first begins by introducing the basic concepts and the \nsignificance of data privacy and security, followed by a discussion about traditional \nmethodolo gies and their associated shortcomings. Moving forward, the center point of \nthis discourse revolves around how AI with its automation and anomaly identification \ncapabilities is transforming this field. Using definitions, case studies, and in -depth \nanalysis , the paper describes the different aspects of predictive analytics, natural \nlanguage processing, machine learning, as prevalent facets of AI applications on \nstrengthening protection mechanisms for data. Subsequently, the paper presents \npractical examples of real -world applications in banking and health care to give an \ninsight on how AI can be integrated into the security system, along with lessons learnt \nfrom such incorporation. A brief examination of the ethical concerns, where despite the \nimmense benefit s that may be derived from AI there is a significant concern on potential \nbiases, surveillance energy as an issue secondly and finally data handling issues is \nperformed to have a comprehensive understanding of AI. The conclusion restates the \nmain points di scussed, underlining the significance of AI in progressing data privacy \nand security and encourages further research and development. The p"
    },
    {
        "paper_name": "Research paper 3.pdf",
        "abstract": "",
        "content": "A Living Review Pipeline for AI/ML Applications in Accelerator Physics\nA. Ghribi\nCNRS – GANIL, Caen, France\n(Dated: October 14, 2025)\nWe present an open-source pipeline for generating aliving reviewof artificial intelligence (AI) and\nmachine learning (ML) applications in accelerator physics and technologies. Traditional review arti-\ncles provide static snapshots that are quickly outdated by the rapid pace of research. The presented\nsystem automatically harvests publications from multiple bibliographic sources (arXiv, InspireHEP,\nHAL, OpenAlex, Crossref, and Springer), deduplicates entries, applies semantic filtering to ensure\naccelerator and ML relevance, and classifies papers into thematic categories. The resulting curated\ndataset was exported in JSON, HTML, PDF, and BibT EXformats, enabling continuous updates\nand integration with web frameworks. We describe the methodology, including semantic similarity\nfiltering using sentence-transformer embeddings, threshold calibration, and expert-informed classi-\nfication. The results demonstrate the robust filtering of∼12000 raw papers/month into a focused\ncorpus of∼2% relevant works. The pipeline provides the basis for an evolving community-driven\nreview of AI/ML in accelerator science.\nI. INTRODUCTION\nArtificial intelligence (AI) and machine learning (ML)\nare reshaping the way scientific research is conceived and\nconducted. In the field of particle accelerators, these\nmethods are increasingly employed for beam dynamics\noptimisation, feedback control, anomaly detection, surro-\ngate modelling, computer vision–based diagnostics, and\nreinforcement learning for autonomous tuning. The pace\nof progress is accelerating: while early efforts were iso-\nlated demonstrations, entire research programs are now\ndevoted to exploring AI and ML as key enablers of next-\ngeneration accelerator design and operation [1–3].\nTraditional review articles, while invaluable for consol-\nidating knowledge, inevitably provide only astatic snap-\nshotof a "
    },
    {
        "paper_name": "Research paper 4.pdf",
        "abstract": "",
        "content": "This is the author’s accepted version of the article. The final version published by IEEE is R. Soundrarajan, C. Fiandrino, M. Polese,\nSalvatore D’Oro, L. Bonati, and T. Melodia, “On AI Verification in Open RAN,” , IEEE COMMAG, 2025, pp. TBD, doi: TBD.\n©2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or\nfuture media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for\nresale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.IEEE COMMUNICATIONS MAGAZINE, VOL. XX, NO. XX, MAY 2025 1\nOn AI Verification in Open RAN\nRahul Soundrarajan , Claudio Fiandrino ,Member, IEEE,Michele\nPolese ,Member, IEEE,Salvatore D’Oro ,Member, IEEE,\nLeonardo Bonati ,Member, IEEE,and Tommaso Melodia ,Fellow, IEEE\nAbstract—Open RAN introduces a flexible, cloud-based\narchitecture for the Radio Access Network ( RAN ), enabling\nArtificial Intelligence ( AI)/Machine Learning ( ML)-driven\nautomation across heterogeneous, multi-vendor deploy-\nments. While EXplainable Artificial Intelligence ( XAI)\nhelps mitigate the opacity of AI models, explainability\nalone does not guarantee reliable network operations. In\nthis article, we propose a lightweight verification approach\nbased on interpretable models to validate the behavior\nof Deep Reinforcement Learning ( DRL ) agents for RAN\nslicing and scheduling in Open RAN. Specifically, we\nuse Decision Tree ( DT)-based verifiers to perform near-\nreal-time consistency checks at runtime, which would be\notherwise unfeasible with computationally expensive state-\nof-the-art verifiers. We analyze the landscape of XAI and\nAIverification, propose a scalable architectural integration,\nand demonstrate feasibility with a DT-based slice-verifier.\nWe also outline future challenges to ensure trustworthy AI\nadoption in Open RAN.\nIndex Terms—Open RAN, AI verification, XAI.\nI. "
    },
    {
        "paper_name": "Research paper 5.pdf",
        "abstract": "",
        "content": "Measuring the Impact of Early-2025 AI on\nExperienced Open-Source Developer Productivity\nJoel Becker∗, Nate Rush∗, Beth Barnes, David Rein\nModel Evaluation & Threat Research (METR)\nAbstract\nDespite widespread adoption, the impact of AI tools on software development in\nthe wild remains understudied. We conduct a randomized controlled trial (RCT)\nto understand how AI tools at the February–June 2025 frontier affect the produc-\ntivity of experienced open-source developers. 16 developers with moderate AI\nexperience complete 246 tasks in mature projects on which they have an aver-\nage of 5 years of prior experience. Each task is randomly assigned to allow or\ndisallow usage of early-2025 AI tools. When AI tools are allowed, developers\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet. Be-\nfore starting tasks, developers forecast that allowing AI will reduce completion\ntime by 24%. After completing the study, developers estimate that allowing AI\nreduced completion time by 20%. Surprisingly, we find that allowing AI actually\nincreases completion time by 19%—AI tooling slowed developers down. This\nslowdown also contradicts predictions from experts in economics (39% shorter)\nand ML (38% shorter). To understand this result, we collect and evaluate evi-\ndence for 21 properties of our setting that a priori could contribute to the observed\nslowdown effect—for example, the size and quality standards of projects, or prior\ndeveloper experience with AI tooling. Although the influence of experimental ar-\ntifacts cannot be entirely ruled out, the robustness of the slowdown effect across\nour analyses suggests it is unlikely to primarily be a function of our experimental\ndesign.\n1 Introduction\nSoftware development is an important part of the modern economy, and a key domain for under-\nstanding and forecasting AI capabilities [1; 2]. Frontier AI systems demonstrate impressive capabil-\nities on a wide range of software benchmarks [3; 4; 5; 6; 7; 8; 9] and in experime"
    },
    {
        "paper_name": "Research paper 6.pdf",
        "abstract": "",
        "content": "arXiv:2507.02554v1  [cs.AI]  3 Jul 2025\nAI Research Agents for Machine Learning: Search,\nExploration, and Generalization in MLE-bench\nEdan Toledo1,2,∗,Karen Hambardzumyan1,2,∗,Martin Josifoski1,∗,Rishi Hazra3,†,Nicolas Baldwin1,\nAlexis Audran-Reiss1,Michael Kuchnik1,Despoina Magka1,Minqi Jiang1,Alisia Maria Lupidi1,Andrei\nLupu1,Roberta Raileanu1,Kelvin Niu1,Tatiana Shavrina1,Jean-Christophe Gagnon-Audet1,Michael\nShvartsman1,Shagun Sodhani1,Alexander H. Miller1,Abhishek Charnalia1,Derek Dunfield1,Carole -Jean\nWu1,Pontus Stenetorp2,Nicola Cancedda1,Jakob Nicolaus Foerster1,Yoram Bachrach1\n1FAIR at Meta,2University College London,3Örebro University\n∗Equal contribution (author order determined by a game of UNO) ,†Work done while at Meta\nAI research agents are demonstrating great potential to accelerate scientific progress by automating\nthe design, implementation, and training of machine learning models. We focus on methods for\nimproving agents’ performance on MLE-bench, a challenging benchmark where agents compete in\nKaggle competitions to solve real-world machine learning problems. We formalize AI research agents\nas search policies that navigate a space of candidate solutions, iteratively modifying them using\noperators. By designing and systematically varying different operator sets and search policies (Greedy,\nMCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our\nbest pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite,\nincreasing the success rate of achieving a Kaggle medal from 39.6 % to 47.7 %. Our investigation\nunderscores the importance of jointly considering the search strategy, operator design, and evaluation\nmethodology in advancing automated machine learning.\nDate:July 4, 2025\nCorrespondence: Edan Toledo at edantoledo@meta.com , Karen Hambardzumyan at mahnerak@meta.com ,\nMartin Josifoski at martinjosifoski@meta.com , Yoram Bachrach at yorambac@meta.com\nCode: https://githu"
    },
    {
        "paper_name": "Research paper 7.pdf",
        "abstract": "",
        "content": "1\nMachine Learning Testing:\nSurvey, Landscapes and Horizons\nJie M. Zhang*, Mark Harman, Lei Ma, Y ang Liu\nAbstract —This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing\n(ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components\n(e.g., the data, learning program, and framework), testing workﬂow (e.g., test generation and test evaluation), and application scenarios\n(e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research\nfocus, concluding with research challenges and promising research directions in ML testing.\nIndex Terms —machine learning, software testing, deep neural network,\nF\n1 I NTRODUCTION\nThe prevalent applications of machine learning arouse\nnatural concerns about trustworthiness. Safety-critical ap-\nplications such as self-driving systems [1], [2] and medical\ntreatments [3], increase the importance of behaviour relating\nto correctness, robustness, privacy, efﬁciency and fairness.\nSoftware testing refers to any activity that aims to detect\nthe differences between existing and required behaviour [4].\nWith the recent rapid rise in interest and activity, testing\nhas been demonstrated to be an effective way to expose\nproblems and potentially facilitate to improve the trustwor-\nthiness of machine learning systems.\nFor example, DeepXplore [1], a differential white-box\ntesting technique for deep learning, revealed thousands of\nincorrect corner case behaviours in autonomous driving\nlearning systems; Themis [5], a fairness testing technique\nfor detecting causal discrimination, detected signiﬁcant ML\nmodel discrimination towards gender, marital status, or race\nfor as many as 77.2% of the individuals in datasets to which\nit was applied.\nIn fact, some aspects of the testing problem for machine\nlearning systems are shared with well-known solutions\nalready widely"
    },
    {
        "paper_name": "Research paper 8.pdf",
        "abstract": "",
        "content": "Integrating Explainable AI for Energy Efficient\nOpen Radio Access Networks\nL. Malakalapalli$, V . Gudepu$, B. Chirumamilla†, S.J. Yadhunandan$•, K. Kondepu$\n$Indian Institute of Technology Dharwad, Dharwad, India.\n†Rutgers University, USA.\n•Boston University, Boston, USA.\ne-mail: cs23ms001@iitdh.ac.in, 212011003@iitdh.ac.in, k.kondepu@iitdh.ac.in\nAbstract —The Open Radio Access Network (Open RAN) is\nan emerging idea — transforming the traditional Radio Access\nNetworks (RAN) that are monolithic and inflexible into more\nflexible and innovative. By leveraging open standard interfaces,\ndata collection across all RAN layers becomes feasible, paving\nthe way for the development of energy-efficient Open RAN\narchitectures through Artificial Intelligence / Machine Learning\n(AI/ML). However, the inherent complexity and black-box nature\nof AI/ML models used for energy consumption prediction pose\nchallenges in interpreting their underlying factors and relation-\nships. This work presents an integration of eXplainable AI (XAI)\nto understand the key RAN parameters that contribute to energy\nconsumption. Furthermore, the paper delves into the analysis of\nRAN parameters — airtime ,goodput ,throughput ,buffer status\nreport ,number of resource blocks , and many others — identified\nby XAI techniques, highlighting their significance in energy\nconsumption.\nIndex Terms —Radio Access Network (RAN), Open RAN,\neXplainable AI (XAI), Energy consumption.\nI. I NTRODUCTION\nThe United Nations (UN) aims at achieving the seventeen\nSustainable Development Goals (SDGs) to create a better\nfuture for the generations to come by 2030 [1]. Among in-\ndustries, Information and Communication Technologies (ICT),\nincluding wireless networks, plays a key role in achieving\nSDG-13:Climate Action. The ongoing development of Beyond\n5G (B5G) networks aligns with SDGs, focusing on reducing\nenergy consumption and carbon footprint. Given the ICT\nsector’s commitment to sustainability, there is a need to re-\nduce energy con"
    },
    {
        "paper_name": "Research paper 9.pdf",
        "abstract": "",
        "content": " \nhttps://iaeme.com/Home/journal/ IJCSCT  1 editor@iaeme.com  International Journal of Computer Scientist (IJCSCT)  \nVolume 2, Issue 1, January -June (2025), pp. 1-7, Article ID:  IJCSCT _02_01_001 \nAvailable online at https://iaeme.com/Home/issue/ IJCSCT ?Volume= 2&Issue= 1 \nJournal ID: 8381 -9009   \n                                                                                                         \n© IAEME Publication        \nEXPLAINABLE ARTIFICIAL INTELLIGENCE \nMODELS FOR TRANSPARENT AND \nTRUSTWORTHY DECISION SUPPORT \nSYSTEMS  \nAlex  Fernando  \nAI Governance Analyst , Spain . \n \nABSTRACT  \nDecision support systems increasingly rely on artificial intelligence to enhance \naccuracy, efficiency, and automation across domains such as healthcare, finance, \nengineering, and governance. However, the opacity of many advanced artificial \nintelligence mod els has raised concerns regarding transparency, accountability, and \ntrust. Explainable artificial intelligence models address these concerns by providing \ninterpretable insights into model behavior and decision logic. This paper examines the \nrole of explain able artificial intelligence in developing transparent and trustworthy \ndecision support systems. It presents conceptual foundations, modeling approaches, \nsystem architectures, and evaluation metrics that support explainability.  \nKeywords:  Explainable Artificial Intelligence, Decision Support Systems, Model \nTransparency, Trustworthy AI, Interpretability, Responsible AI  \n \nCite this Article:  Alex Fernando . (2025). Explainable Artificial Intelligence Models for \nTransparent and Trustworthy Decision Support Systems . International Journal of Computer \nScientist (IJCSCT) , 2(1), 1-7. \nhttps://iaeme.com/MasterAdmin/ Journal_uploads/ IJCSCT /VOLUME_ 2_ISSUE_ 1/IJCSCT _02_01_001.Pdf \n \nAlex Fernando  \nhttps://iaeme.com/Home/journal/ IJCSCT    2 editor@iaeme.com  1. Introduction  \nDecision support systems play a critical role in assisting human decision -makers by"
    }
]